{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segformer\n",
    "\n",
    "Implementation adapted from: https://github.com/NVlabs/SegFormer\n",
    "\n",
    "Research Paper: https://arxiv.org/abs/2105.15203\n",
    "\n",
    "Datasets: https://data.mendeley.com/datasets/8gf9vpkhgy/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\duong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from transformers import SegformerConfig, SegformerModel, TrainingArguments, AutoImageProcessor, SegformerForSemanticSegmentation\n",
    "from transformers import Trainer\n",
    "from einops import rearrange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Darwin Dataset\n",
    "\n",
    "This section will go through the implementation of Segformer using the Darwin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation adapted from: https://www.youtube.com/watch?v=-AejMcdeOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in Folder: 6106\n",
      "Mask Images in Folder: 6106\n"
     ]
    }
   ],
   "source": [
    "Height = 256\n",
    "Width = 256\n",
    "\n",
    "path = \"./Datasets/Darwin/\"\n",
    "imagePath = path + \"img/*.png\"\n",
    "maskPath = path + \"img/*.png\"\n",
    "\n",
    "listOfImages = glob.glob(imagePath)\n",
    "listofMaskImages = glob.glob(maskPath)\n",
    "\n",
    "print(\"Images in Folder:\", len(listOfImages))\n",
    "print(\"Mask Images in Folder:\", len(listofMaskImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6106/6106 [01:38<00:00, 62.06it/s]\n"
     ]
    }
   ],
   "source": [
    "img = []\n",
    "mask = []\n",
    "\n",
    "for imgFiles, maskImgFiles in tqdm(zip(listOfImages, listofMaskImages), total=len(listOfImages)):\n",
    "    images = cv2.imread(imgFiles, cv2.IMREAD_COLOR)\n",
    "    images = cv2.resize(images, (Width, Height))\n",
    "    images = images / 255.0\n",
    "    images = images.astype(np.float32)\n",
    "    img.append(images)\n",
    "\n",
    "    maskImages = cv2.imread(maskImgFiles, cv2.IMREAD_GRAYSCALE)\n",
    "    maskImages = cv2.resize(maskImages, (Width, Height))\n",
    "    maskImages[maskImages>0] = 1\n",
    "    mask.append(maskImages)\n",
    "\n",
    "img = np.array(img)\n",
    "mask = np.array(mask)\n",
    "mask = mask.astype(int)\n",
    "\n",
    "train_imgs, val_imgs = train_test_split(img, test_size=0.1, random_state=10)\n",
    "train_mask, val_mask = train_test_split(mask, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model Implementation\n",
    "\n",
    "Implemenation adapted from: https://github.com/FrancescoSaverioZuppichini/SegFormer\n",
    "\n",
    "https://github.com/huggingface/blog/blob/main/fine-tune-segformer.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "c:\\Users\\duong\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:101: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
