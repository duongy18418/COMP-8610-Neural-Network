{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\nfrom imutils import paths\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom tqdm import tqdm\nimport os\nimport pandas as pd\nfrom torchvision.datasets.flickr import glob\nfrom torchvision.io import read_image, ImageReadMode\nfrom torchvision.transforms.functional import resize\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport lightning as L\nimport pandas as pd\nfrom torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryJaccardIndex, BinaryPrecision, BinaryRecall\nfrom lightning.pytorch.loggers import CSVLogger\nfrom torchmetrics.segmentation import MeanIoU\nimport io\nimport matplotlib.pyplot as plt\n\nclass SegImageDataset(Dataset):\n    def __init__(self, imgs, masks):\n        self.imgs = imgs\n        self.masks = masks\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, idx):\n        image = read_image(self.imgs[idx], ImageReadMode.RGB).float() / 255.0\n        mask = torch.argmax(read_image(self.masks[idx], ImageReadMode.GRAY_ALPHA), dim=0).long()\n        \n        if not (image.shape[0] == mask.shape[0] and image.shape[0] == mask.shape[0]):\n            image = resize(image, mask.shape)\n        # binary_mask = torch.where(masked < 0.5, torch.tensor(0), torch.tensor(1))\n        return image, mask\n    \nclass SegDM(L.LightningDataModule):\n    def __init__(self, batch_size, img_dir, mask_dir):\n        super().__init__()\n        # read and sort images.\n        self.image_paths = sorted(list(paths.list_images(img_dir)))\n        self.mask_paths = sorted(list(paths.list_images(mask_dir)))\n        self.batch_size = batch_size\n    \n    def setup(self, stage: str):\n        fit_imgs, test_imgs, fit_masks, test_masks = train_test_split(self.image_paths, self.mask_paths, test_size=0.25, random_state=42)\n        if stage == \"fit\":\n            train_imgs, val_imgs, train_masks, val_masks = train_test_split(fit_imgs, fit_masks, test_size=0.25, random_state=42)\n            self.train = SegImageDataset(imgs=train_imgs, masks=train_masks)\n            self.val = SegImageDataset(imgs=val_imgs, masks=val_masks)\n            print(f\"{len(self.train)} examples in the training set...\")\n            print(f\"{len(self.val)} examples in the validation set...\")\n        if stage == \"test\":\n            self.test = SegImageDataset(imgs=test_imgs, masks=test_masks)\n            print(f\"{len(self.test)} examples in the test set...\")\n\n    def train_dataloader(self):\n        return DataLoader(self.train, shuffle=True, batch_size=self.batch_size, num_workers=0)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val, shuffle=False, batch_size=self.batch_size, num_workers=0)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test, shuffle=False, batch_size=self.batch_size, num_workers=0)\n    \n\nclass SegModule(L.LightningModule):\n    def __init__(self, model, num_classes, learning_rate=0.001, result_path='test_result.csv'):\n        \"\"\"\n        model: any pytorch model\n        num_classes: number of labels for pixels\n        result_path: csv file path for test result\n        \"\"\"\n        super().__init__()\n        self.model = model\n        self.loss_fn = torch.nn.CrossEntropyLoss()\n        self.lr = learning_rate \n        self.result_path=result_path\n        self.save_hyperparameters(ignore=['model', 'result_path'])\n        \n        self.test_results = {'f1': [], 'accuracy': [], 'precision': [], 'recall': [], 'mean_iou': []}\n        self.f1 = BinaryF1Score()\n        self.accuracy = BinaryAccuracy()\n        self.recall = BinaryRecall()\n        self.precision = BinaryPrecision()\n        self.mean_iou = MeanIoU(num_classes)\n    \n    def common_steps(self, batch):\n        imgs, masks = batch\n        preds = self.model(imgs)\n        loss = self.loss_fn(preds, masks)\n        return loss, preds, masks\n\n    def training_step(self, batch):\n        loss, _, _ = self.common_steps(batch)\n        self.log('train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch):\n        loss, _, _ = self.common_steps(batch)\n        self.log('val_loss', loss)\n        return loss\n    \n    def test_step(self, batch):\n        loss, preds, masks = self.common_steps(batch)\n        self.log('test_loss', loss)\n        preds = torch.argmax(preds, dim=1)\n        # masks = torch.argmax(masks, dim=1)\n        for metric_name in self.test_results.keys():\n            metric = getattr(self, metric_name)\n            self.test_results[metric_name].append(\n                metric(preds, masks).item()\n            )\n        return loss\n    \n    def predict_step(self, test_image):\n        test_image = test_image.unsqueeze(0)\n        # Generate prediction\n        output = self.model(test_image)\n        prediction = torch.argmax(output, 0)\n        return prediction\n    \n    def on_test_end(self):\n        df = pd.DataFrame(self.test_results)\n        df.to_csv(self.result_path, index=None)\n    \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n    \ndef get_segmentation_plot(trained_model, test_data, device, start_idx=0, end_idx=3):\n    figs = []\n\n    for i in range(start_idx, end_idx):\n        test_image, test_mask = test_data[i]\n        out = trained_model(test_image.to(device).unsqueeze(0))[0]\n        prediction = torch.argmax(out, 0)\n\n        fig, ax = plt.subplots(1, 3, figsize=(12, 8))\n        ax[0].imshow(test_image.permute(1, 2, 0))\n        ax[1].imshow(test_mask, cmap='gray', vmin=0, vmax=1, origin='lower')\n        ax[2].imshow(prediction.detach().cpu().numpy(), cmap='gray', vmin=0, vmax=1, origin='lower')\n\n        ax[0].set_title('Test Image')\n        ax[1].set_title('Actual Mask')\n        ax[2].set_title('Predicted Mask')\n\n        figs.append(fig)\n\n    return figs","metadata":{"_uuid":"2125e907-62e5-42f2-b2ef-38a3a6c89829","_cell_guid":"9bf3f72a-f2f3-4c21-9e2b-7c9e503cecdc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}